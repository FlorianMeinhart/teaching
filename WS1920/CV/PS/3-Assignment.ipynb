{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxCe-p9LIXRu"
   },
   "source": [
    "# Assignment 3 (15 points)\n",
    "(due on Nov. 25, 11pm)\n",
    "\n",
    "In the third assignment, we will write a **Convolutional Neural Network (CNN)** together with training and evaluation routines.\n",
    "\n",
    "The task description can be found [below](#Task).\n",
    "\n",
    "**Important**: I strongly recommend to use *Google Collab (GC)* for this assignment. Make yourself familiar with running Jupyter notebooks on GC (especially selecting the right runtime, i.e., Python 3 + GPU). This will make your life a lot easier, as training will be faster and you can easily debug problems in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3018,
     "status": "ok",
     "timestamp": 1573722068948,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBf7BGV1l2b7ymP7ol7FhK8GOHj3X5u0PyNhETx=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "CeswLxlcE28m",
    "outputId": "62ca02c8-4b83-4682-a6ea-2d01607c79eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train on cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Torchvision imports\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Numpy and other stuff\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter\n",
    "\n",
    "torch.manual_seed(1234);\n",
    "np.random.seed(1234);\n",
    "\n",
    "# Check if we have a CUDA-capable device; if so, use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Will train on {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18661,
     "status": "ok",
     "timestamp": 1573722139513,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBf7BGV1l2b7ymP7ol7FhK8GOHj3X5u0PyNhETx=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "eOSdQelkMPAd",
    "outputId": "326dae9f-72ff-4570-9e27-4d19973b37f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 transforms (random horizontal flipping + mean/std. dev. normalize)\n",
    "cifar10_transforms = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "         \n",
    "# Load full training data\n",
    "ds_train = CIFAR10('/tmp/cifar', \n",
    "                 train=True, \n",
    "                 transform=cifar10_transforms, \n",
    "                 target_transform=None, \n",
    "                 download=True)\n",
    "\n",
    "# Load full testing data \n",
    "ds_test = CIFAR10('/tmp/cifar', \n",
    "                 train=False, \n",
    "                 transform=cifar10_transforms,\n",
    "                 target_transform=None, \n",
    "                 download=True)\n",
    "\n",
    "lab = [ds_train[x][1] for x in range(len(ds_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGmz9GEKRuvw"
   },
   "outputs": [],
   "source": [
    "def generate_train_indices(n_splits, train_size, lab):\n",
    "    s = StratifiedShuffleSplit(\n",
    "        n_splits=n_splits, \n",
    "        train_size=train_size, \n",
    "        test_size=None)\n",
    "    \n",
    "    return [i.tolist() for i, _ in s.split(lab, lab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGYPAsbwR77Z"
   },
   "outputs": [],
   "source": [
    "classes = ['plane', \n",
    "           'car', \n",
    "           'bird', \n",
    "           'cat',\n",
    "           'deer', \n",
    "           'dog', \n",
    "           'frog', \n",
    "           'horse', \n",
    "           'ship', \n",
    "           'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxTbKsZnSC-2"
   },
   "outputs": [],
   "source": [
    "def show_images(ds: torchvision.datasets.cifar.CIFAR10, \n",
    "                indices: list):\n",
    "    \n",
    "    assert np.max(indices) < len(ds)\n",
    "    \n",
    "    plt.figure(figsize=(9, len(indices)));\n",
    "    for j,idx in enumerate(indices):\n",
    "        plt.subplot(1,len(indices),j+1)\n",
    "        plt.imshow(ds[idx][0].permute(1,2,0).numpy())\n",
    "        plt.title('Label={}'.format(classes[ds[idx][1]]),fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ElEkUGgJ86C"
   },
   "source": [
    "## Tasks\n",
    "\n",
    "The assignment is split into 4 parts: \n",
    "\n",
    "1. Writing the model definition\n",
    "2. Writing the training code\n",
    "3. Writing the testing code\n",
    "4. Writing the *glue* code for training/testing\n",
    "\n",
    "*First*, implement the following **convolutional neural network (CNN)**: It consists of 3 blocks and a simple linear classifier at the end.\n",
    "\n",
    "My notation denotes the following:\n",
    "\n",
    "- `Conv2D(in_channels, out_channels, kernel_size, padding)` - 2D Convolution\n",
    "- `MaxPool(kernel_size, stride, padding)` - Max. pooling\n",
    "- `AvgPool(kernel_size, stride, padding)` - Avg. pooling\n",
    "- `Dropout(dropout_probability)` - Dropout layer\n",
    "- `BatchNorm2D` - 2D batch normalization\n",
    "\n",
    "All these operations can also be found in the [PyTorch documentaton](https://pytorch.org/docs/stable/index.html).\n",
    "\n",
    "**Block 1**\n",
    "\n",
    "```\n",
    "Conv2D(  3,128,3,1) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "Conv2D(128,128,3,1) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "Conv2D(128,128,3,1) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "MaxPool(2,2,0)\n",
    "Dropout(0.5)\n",
    "```\n",
    "The output size at that point should be $N \\times 128 \\times 16 \\times 16$.\n",
    "\n",
    "**Block 2**\n",
    "\n",
    "```\n",
    "Conv2D(128,256,3,1) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "Conv2D(256,256,3,1) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "Conv2D(256,256,3,1) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "MaxPool(2,2,0)\n",
    "Dropout(0.5)\n",
    "```\n",
    "The output size at that point should be $N \\times 128 \\times 8 \\times 8$.\n",
    "\n",
    "**Block 3**\n",
    "\n",
    "```\n",
    "Conv2D(256,512,3,0) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "Conv2D(512,256,1,0) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "Conv2D(256,128,1,0) -> Batchnorm2D -> LeakyReLU(0.1)\n",
    "AvgPool(6,2,0)\n",
    "Dropout(0.5)\n",
    "```\n",
    "The output size at that point should be $N \\times 128 \\times 1 \\times 1$.\n",
    "\n",
    "**Classifier**\n",
    "\n",
    "View the output of the last block as a $1 \\times 128$ tensor and add a \n",
    "linear layer mapping from $\\mathbb{R}^{128} \\rightarrow \\mathbb{R}^{10}$\n",
    "(include bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "text",
    "id": "YDCXdZUSKzAY"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module): \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # YOUR CODE GOES HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE GOES HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can quickly test your network definition with ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 953,
     "status": "ok",
     "timestamp": 1573722177068,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBf7BGV1l2b7ymP7ol7FhK8GOHj3X5u0PyNhETx=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "BhtMSe7TSHo6",
    "outputId": "89a7a8e1-cfb8-4959-c2c6-d71af6a4cd33"
   },
   "outputs": [],
   "source": [
    "net = ConvNet(10)\n",
    "out = net(torch.rand(5,3,32,32))\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duG26vY27GJ9"
   },
   "source": [
    "Write a **training method** which takes the `model`, the `device`, the current loader for the training data, the `optimizer` and the current epoch as parameters. The training method should also print the accumulated cross-entropy loss over each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vB6ibYt1SMhg"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # YOUR CODE GOES HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, write a **testing method** which takes the `model`, the `device` and the testing data loader as parameters and evaluates the model on the testing split of CIFAR10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HsHPvlm1SVht"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "   # YOUR CODE GOES HERE\n",
    "    pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1573722206746,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBf7BGV1l2b7ymP7ol7FhK8GOHj3X5u0PyNhETx=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "OXEkyYPjSPye",
    "outputId": "be2108f3-ca1a-4ab8-dd55-e337bf2ed5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 50, 3: 50, 8: 50, 6: 50, 9: 50, 0: 50, 4: 50, 7: 50, 1: 50, 5: 50})\n"
     ]
    }
   ],
   "source": [
    "train_indices = generate_train_indices(10, 500, lab)\n",
    "ds_train_subset = Subset(ds_train, train_indices[1])\n",
    "print(Counter([ds_train_subset[i][1] for i in range(len(ds_train_subset))]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ds_train_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    ds_test, \n",
    "    batch_size=64, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hByDU-eF7rjY"
   },
   "source": [
    "Finally, write the *glue* code which iterates over `n_epochs` (e.g., 100) and, in each epoch, calls `train(...)` and `test(...)`. Train the model using **SGD** with a learning rate of 0.01 and momentum of 0.9 for 100 epochs.\n",
    "After every 10th epoch, evaluate the current model on the testing data and print the current accuracy.\n",
    "\n",
    "**Bonus (2 points)**: Add a learning rate scheduler which divides the learning rate into half after each 30th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 174874,
     "status": "ok",
     "timestamp": 1573722386555,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBf7BGV1l2b7ymP7ol7FhK8GOHj3X5u0PyNhETx=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "Cx2ahoZnSRqP",
    "outputId": "0ba12fa9-dc66-44ca-8147-202b482ad2b6"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pft0JDgJ9mgz"
   },
   "source": [
    "If you train with reasonable settings, you should get a testing accuracy somewhere between 45% and 50% (random chance is 1/10 obviously)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
